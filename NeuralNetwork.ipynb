{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jpIhl--bx6BA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "df_train = pd.read_csv('/content/drive/MyDrive/nn_train.csv')\n",
        "df_test = pd.read_csv('/content/drive/MyDrive/nn_test.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSfnG2ISgtOM",
        "outputId": "e761ab1e-8f51-4f25-b821-762afa752722"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_x = df_train.iloc[:, 1:-2]\n",
        "y_binary = df_train.iloc[:,-2]\n",
        "df_test_x = df_test.iloc[:, 1:]\n",
        "X = (df_train_x - df_train_x.mean())/df_train_x.std()\n",
        "x_test = (df_test_x - df_train_x.mean())/df_train_x.std()\n",
        "print(X.shape)\n",
        "print(x_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZoiaO9phlFd",
        "outputId": "9942e3e5-d696-47ee-a4bc-bf905a7db3a7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(80000, 1024)\n",
            "(20000, 1024)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))"
      ],
      "metadata": {
        "id": "dwKaxrNwtY6H"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid_derivative(z):\n",
        "    return sigmoid(z) * (1 - sigmoid(z))"
      ],
      "metadata": {
        "id": "VGn8Or67thDk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_parameters(input_size, hidden_size, output_size):\n",
        "    W1 = np.random.randn(input_size + 1, hidden_size) * 0.01\n",
        "    W2 = np.random.randn(hidden_size + 1, output_size) * 0.01\n",
        "    return W1, W2"
      ],
      "metadata": {
        "id": "0Lresc-0vPK_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_propagation(X, W1, W2):\n",
        "    X1 = np.hstack((X, np.ones((X.shape[0], 1))))\n",
        "    Z1 = np.dot(X1, W1)\n",
        "    A1 = sigmoid(Z1)\n",
        "    A1_bias = np.hstack((A1, np.ones((A1.shape[0], 1))))\n",
        "    Z2 = np.dot(A1_bias, W2)\n",
        "    A2 = sigmoid(Z2)\n",
        "    bla = {\"X1\": X1, \"Z1\": Z1, \"A1\": A1_bias, \"Z2\": Z2, \"A2\": A2}\n",
        "    return A2, bla"
      ],
      "metadata": {
        "id": "KZUpbULD0ftP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def backward_propagation(y, bla, W2):\n",
        "    m = y.shape[0]\n",
        "    A1, A2 = bla[\"A1\"], bla[\"A2\"]\n",
        "    dZ2 = A2 - y.reshape(-1, 1)\n",
        "    dW2 = np.dot(A1.T, dZ2) / m\n",
        "    dZ1 = np.dot(dZ2, W2[:-1].T) * sigmoid_derivative(bla[\"Z1\"])\n",
        "    dW1 = np.dot(bla[\"X1\"].T, dZ1) / m\n",
        "    grads = {\"dW1\": dW1, \"dW2\": dW2}\n",
        "    return grads"
      ],
      "metadata": {
        "id": "vfU0aBtC0iz5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_parameters(W1, W2, grads, learning_rate):\n",
        "    W1 -= learning_rate * grads[\"dW1\"]\n",
        "    W2 -= learning_rate * grads[\"dW2\"]\n",
        "    return W1, W2"
      ],
      "metadata": {
        "id": "8U3SVf_U0o-a"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(X, y, hidden_size, learning_rate, iterations):\n",
        "    input_size = X.shape[1]\n",
        "    output_size = 1\n",
        "    W1, W2 = initialize_parameters(input_size, hidden_size, output_size)\n",
        "    losses = []\n",
        "    for iteration in range(iterations):\n",
        "\n",
        "        A2, bla = forward_propagation(X, W1, W2)\n",
        "        loss = -np.mean(y * np.log(A2) + (1 - y) * np.log(1 - A2))\n",
        "        losses.append(loss)\n",
        "\n",
        "        grads = backward_propagation(y, bla, W2)\n",
        "\n",
        "        W1, W2 = update_parameters(W1, W2, grads, learning_rate)\n",
        "\n",
        "        if iteration % 100 == 0:\n",
        "            print(f\"Iteration {iteration}: Loss = {loss:.4f}\")\n",
        "\n",
        "    return W1, W2, loss"
      ],
      "metadata": {
        "id": "R6_UeOge0vEl"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(X, W1, W2):\n",
        "    A2, _ = forward_propagation(X, W1, W2)\n",
        "    return (A2 > 0.5).astype(int)"
      ],
      "metadata": {
        "id": "SoBGuhsc00cI"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "  hidden_size = 4\n",
        "  learning_rate = 0.1\n",
        "  iterations = 1000\n",
        "  W1, W2, losses = train(X, y_binary, hidden_size, learning_rate, iterations)\n",
        ""
      ],
      "metadata": {
        "id": "cqCyDy1q1TIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(losses)\n",
        "    plt.title(\"Loss Curve\")\n",
        "    plt.xlabel(\"Iterations\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "8ewlY_aK1wYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C25bF8Em11iE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dLNrSVzs3amE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}